"""
Generator - æ–‡æ¡£ç”Ÿæˆæ¨¡å—

åŠŸèƒ½:
- ç”Ÿæˆé£ä¹¦æ–‡æ¡£
- ç”ŸæˆMarkdownæ–‡ä»¶
- ä¸Šä¼ å›¾ç‰‡
"""

import asyncio
from datetime import datetime
from pathlib import Path
from typing import Optional
from loguru import logger

from models import (
    Category, ProcessedArticle, Prediction, PredictionChange, DailyBriefing
)


CATEGORY_INFO = {
    Category.AI: {"name": "AIç±»", "icon": "ğŸ¤–"},
    Category.ROBOTICS: {"name": "æœºå™¨äººç±»", "icon": "ğŸ¦¾"},
    Category.EMBODIED_AI: {"name": "å…·èº«æ™ºèƒ½ç±»", "icon": "ğŸ‘“"},
    Category.SEMICONDUCTOR: {"name": "åŠå¯¼ä½“è¡Œä¸šç±»", "icon": "ğŸ’¾"},
    Category.AUTO: {"name": "æ±½è½¦ç±»", "icon": "ğŸš—"},
    Category.HEALTH: {"name": "å¥åº·åŒ»ç–—ç±»", "icon": "ğŸ¥"},
    Category.ECONOMY: {"name": "ç»æµæ”¿ç­–ç±»", "icon": "ğŸ“Š"},
    Category.BUSINESS: {"name": "å•†ä¸šç§‘æŠ€ç±»", "icon": "ğŸ’¼"},
    Category.POLITICS: {"name": "æ”¿æ²»æ”¿ç­–ç±»", "icon": "ğŸ›ï¸"},
    Category.INVESTMENT: {"name": "æŠ•èµ„è´¢ç»ç±»", "icon": "ğŸ“ˆ"},
    Category.CONSUMER_ELECTRONICS: {"name": "æ¶ˆè´¹ç”µå­ç±»", "icon": "ğŸ“±"},
    Category.KEY_PEOPLE: {"name": "å…³é”®äººç‰©å‘è¨€", "icon": "ğŸ¤"},
}


class MarkdownGenerator:
    """Markdownç”Ÿæˆå™¨"""
    
    def __init__(self, output_dir: str = "output"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def _format_article(self, article: ProcessedArticle, index: int) -> str:
        """æ ¼å¼åŒ–å•ç¯‡æ–‡ç« """
        parts = []
        
        # åŒè¯­æ ‡é¢˜
        parts.append(f"### {index}. {article.title_original}")
        parts.append(f"### {article.title_zh}")
        parts.append("")
        
        # å…ƒä¿¡æ¯
        parts.append(f"**æ¥æº:** {article.source} | **æ—¶é—´:** {article.published_at.strftime('%Y-%m-%d %H:%M')}")
        parts.append("")
        
        # æåŠçš„å…³é”®äººç‰©
        if article.mentioned_people:
            parts.append(f"**æåŠäººç‰©:** {', '.join(article.mentioned_people)}")
            parts.append("")
        
        # è¯¦ç»†æ‘˜è¦
        parts.append("**ğŸ“° è¯¦ç»†æ‘˜è¦:**")
        parts.append("")
        parts.append(article.summary_zh)
        parts.append("")
        
        # å…³é”®è¦ç‚¹
        if article.key_points:
            parts.append("**ğŸ”‘ å…³é”®è¦ç‚¹:**")
            for point in article.key_points:
                parts.append(f"- {point}")
            parts.append("")
        
        # å½±å“åˆ†æ
        if article.impact_analysis:
            parts.append("**ğŸ“ˆ å½±å“åˆ†æ:**")
            parts.append(article.impact_analysis)
            parts.append("")
        
        # åŸæ–‡é“¾æ¥
        parts.append(f"**ğŸ”— åŸæ–‡é“¾æ¥:** [{article.url}]({article.url})")
        parts.append("")
        
        # å›¾ç‰‡
        if article.images:
            parts.append("**ğŸ–¼ï¸ ç›¸å…³å›¾ç‰‡:**")
            for img in article.images[:3]:  # æœ€å¤š3å¼ 
                parts.append(f"![]({img})")
            parts.append("")
        
        # è§†é¢‘
        if article.video_urls:
            parts.append("**ğŸ“¹ ç›¸å…³è§†é¢‘:**")
            for video in article.video_urls[:2]:  # æœ€å¤š2ä¸ª
                parts.append(f"- {video}")
            parts.append("")
        
        # åˆ†éš”çº¿
        parts.append("---")
        parts.append("")
        
        return "\n".join(parts)
    
    def _format_predictions(
        self,
        predictions: list[Prediction],
        changes: list[PredictionChange]
    ) -> str:
        """æ ¼å¼åŒ–é¢„æµ‹éƒ¨åˆ†"""
        parts = []
        
        timeframe_names = {
            "week": "ğŸ“† æœªæ¥ä¸€å‘¨å…³æ³¨ç‚¹",
            "month": "ğŸ“† æœªæ¥ä¸€ä¸ªæœˆå…³æ³¨ç‚¹",
            "half_year": "ğŸ“† æœªæ¥åŠå¹´å…³æ³¨ç‚¹",
            "year": "ğŸ“† æœªæ¥ä¸€å¹´å…³æ³¨ç‚¹"
        }
        
        for timeframe, name in timeframe_names.items():
            parts.append(f"### {name}")
            parts.append("")
            parts.append("| é¢†åŸŸ | é¢„æµ‹å…³æ³¨ | å˜åŒ–è¯´æ˜ |")
            parts.append("|------|----------|----------|")
            
            tf_predictions = [p for p in predictions if p.timeframe == timeframe]
            tf_changes = {c.category: c for c in changes if c.timeframe == timeframe}
            
            for pred in tf_predictions:
                info = CATEGORY_INFO[pred.category]
                change = tf_changes.get(pred.category)
                
                # æˆªæ–­å†…å®¹ä»¥é€‚åº”è¡¨æ ¼
                content = pred.content[:100] + "..." if len(pred.content) > 100 else pred.content
                content = content.replace("\n", " ").replace("|", "\\|")
                
                if change:
                    change_note = f"â¬†ï¸ {change.reason[:30]}..." if len(change.reason) > 30 else f"â¬†ï¸ {change.reason}"
                else:
                    change_note = "â€”"
                
                parts.append(f"| {info['icon']} {info['name']} | {content} | {change_note} |")
            
            parts.append("")
        
        return "\n".join(parts)
    
    def generate(self, briefing: DailyBriefing) -> str:
        """ç”Ÿæˆå®Œæ•´çš„Markdownæ–‡æ¡£"""
        parts = []
        
        # æ ‡é¢˜
        parts.append("# ğŸ“° å…¨çƒç§‘æŠ€ç®€æŠ¥")
        parts.append("")
        
        # æ—¥æœŸåˆ†éš”
        date_str = briefing.date.strftime("%Yå¹´%mæœˆ%dæ—¥ï¼ˆ%Aï¼‰")
        parts.append("â”" * 50)
        parts.append(f"## ğŸ“… {date_str}")
        parts.append("â”" * 50)
        parts.append("")
        
        # ä»Šæ—¥æ¦‚è§ˆ
        parts.append("## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ")
        parts.append("")
        
        total = sum(len(articles) for articles in briefing.articles_by_category.values())
        parts.append(f"**å…±è®¡ {total} æ¡æ–°é—»**")
        parts.append("")
        
        for category, articles in briefing.articles_by_category.items():
            if articles:
                info = CATEGORY_INFO[category]
                parts.append(f"- {info['icon']} {info['name']}: {len(articles)}æ¡")
        parts.append("")
        
        if briefing.summary:
            parts.append("**ä»Šæ—¥è¦ç‚¹:**")
            parts.append(briefing.summary)
            parts.append("")
        
        parts.append("â”" * 50)
        parts.append("")
        
        # å„åˆ†ç±»æ–°é—»
        for category in Category:
            articles = briefing.articles_by_category.get(category, [])
            if not articles:
                continue
            
            info = CATEGORY_INFO[category]
            parts.append(f"## {info['icon']} {info['name']}")
            parts.append("")
            
            for i, article in enumerate(articles, 1):
                parts.append(self._format_article(article, i))
        
        # é¢„æµ‹éƒ¨åˆ†
        parts.append("â”" * 50)
        parts.append("")
        parts.append("## ğŸ¯ æœªæ¥é¢„æµ‹")
        parts.append("")
        parts.append(self._format_predictions(
            briefing.predictions,
            briefing.prediction_changes
        ))
        
        # ç”Ÿæˆæ—¶é—´
        parts.append("â”" * 50)
        parts.append("")
        parts.append(f"*ç”Ÿæˆæ—¶é—´: {briefing.generated_at.strftime('%Y-%m-%d %H:%M:%S')}*")
        parts.append("")
        
        return "\n".join(parts)
    
    def save(self, briefing: DailyBriefing, filename: Optional[str] = None) -> Path:
        """ä¿å­˜Markdownæ–‡ä»¶"""
        if filename is None:
            filename = f"briefing_{briefing.date.strftime('%Y%m%d')}.md"
        
        content = self.generate(briefing)
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"Saved markdown to {filepath}")
        return filepath


class FeishuGenerator:
    """é£ä¹¦æ–‡æ¡£ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # TODO: åˆå§‹åŒ–é£ä¹¦SDK
        self.doc_id = None
        
    async def create_or_get_doc(self, title: str) -> str:
        """åˆ›å»ºæˆ–è·å–é£ä¹¦æ–‡æ¡£"""
        # TODO: å®ç°é£ä¹¦APIè°ƒç”¨
        # å¦‚æœæ–‡æ¡£å·²å­˜åœ¨ï¼Œè¿”å›doc_id
        # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡æ¡£
        pass
    
    async def append_content(self, doc_id: str, content: str):
        """å‘æ–‡æ¡£è¿½åŠ å†…å®¹"""
        # TODO: å®ç°é£ä¹¦APIè°ƒç”¨
        pass
    
    async def upload_image(self, image_path: str) -> str:
        """ä¸Šä¼ å›¾ç‰‡åˆ°é£ä¹¦"""
        # TODO: å®ç°é£ä¹¦APIè°ƒç”¨
        # è¿”å›å›¾ç‰‡token
        pass
    
    async def generate(self, briefing: DailyBriefing) -> str:
        """ç”Ÿæˆé£ä¹¦æ–‡æ¡£"""
        # TODO: å®Œæ•´å®ç°
        # 1. è·å–æˆ–åˆ›å»ºæ–‡æ¡£
        # 2. ä¸Šä¼ å›¾ç‰‡
        # 3. æ„å»ºé£ä¹¦æ–‡æ¡£å—
        # 4. è¿½åŠ å†…å®¹
        
        logger.info("Feishu document generation - TODO")
        return ""


async def main():
    """æµ‹è¯•ç”Ÿæˆ"""
    from models import DailyBriefing, ProcessedArticle, Prediction, PredictionChange
    
    # æ¨¡æ‹Ÿæ•°æ®
    article = ProcessedArticle(
        id="test1",
        title_original="OpenAI releases GPT-5 with revolutionary capabilities",
        title_zh="OpenAIå‘å¸ƒå…·æœ‰é©å‘½æ€§èƒ½åŠ›çš„GPT-5",
        url="https://techcrunch.com/2026/02/13/openai-gpt5",
        source="TechCrunch",
        published_at=datetime(2026, 2, 13, 9, 30),
        category=Category.AI,
        category_confidence=0.95,
        summary_zh="""OpenAIä»Šæ—¥æ­£å¼å‘å¸ƒäº†å…¶æœ€æ–°ä¸€ä»£å¤§è¯­è¨€æ¨¡å‹GPT-5ï¼Œè¿™æ˜¯ç»§GPT-4ä¹‹åçš„åˆä¸€æ¬¡é‡å¤§é£è·ƒã€‚

æ–°æ¨¡å‹åœ¨å¤šä¸ªå…³é”®æŒ‡æ ‡ä¸Šå®ç°äº†æ˜¾è‘—æå‡ï¼šæ¨ç†èƒ½åŠ›æå‡äº†40%ï¼Œå¤šæ¨¡æ€ç†è§£èƒ½åŠ›å¢å¼ºäº†60%ï¼ŒåŒæ—¶å°†å“åº”å»¶è¿Ÿé™ä½äº†50%ã€‚

GPT-5æœ€å¼•äººæ³¨ç›®çš„æ–°ç‰¹æ€§æ˜¯å…¶"æŒç»­å­¦ä¹ "èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸ç”¨æˆ·çš„äº¤äº’è¿‡ç¨‹ä¸­ä¸æ–­ä¼˜åŒ–è‡ªèº«è¡¨ç°ï¼ŒåŒæ—¶ä¿æŒéšç§å®‰å…¨ã€‚

æ­¤å¤–ï¼ŒGPT-5è¿˜å¼•å…¥äº†å…¨æ–°çš„"ä»£ç†æ¨¡å¼"ï¼ˆAgent Modeï¼‰ï¼Œå…è®¸æ¨¡å‹è‡ªä¸»æ‰§è¡Œå¤æ‚çš„å¤šæ­¥éª¤ä»»åŠ¡ï¼Œè¿™è¢«è§†ä¸ºå‘AGIè¿ˆè¿›çš„é‡è¦ä¸€æ­¥ã€‚

ä¸šå†…åˆ†æå¸ˆè®¤ä¸ºï¼ŒGPT-5çš„å‘å¸ƒå°†è¿›ä¸€æ­¥åŠ é€ŸAIæŠ€æœ¯åœ¨å„è¡Œä¸šçš„åº”ç”¨è½åœ°ï¼ŒåŒæ—¶ä¹Ÿå°†åŠ å‰§ç§‘æŠ€å·¨å¤´ä¹‹é—´çš„AIç«èµ›ã€‚""",
        key_points=[
            "æ¨ç†èƒ½åŠ›æå‡40%ï¼Œå¤šæ¨¡æ€èƒ½åŠ›æå‡60%",
            "å¼•å…¥'æŒç»­å­¦ä¹ 'èƒ½åŠ›",
            "å…¨æ–°'ä»£ç†æ¨¡å¼'æ”¯æŒå¤æ‚ä»»åŠ¡è‡ªä¸»æ‰§è¡Œ",
            "å“åº”å»¶è¿Ÿé™ä½50%"
        ],
        impact_analysis="GPT-5çš„å‘å¸ƒå°†æ¨åŠ¨AIåº”ç”¨è¿›å…¥æ–°é˜¶æ®µï¼Œé¢„è®¡å°†åŠ é€Ÿä¼ä¸šAIè½¬å‹è¿›ç¨‹ï¼ŒåŒæ—¶å¯èƒ½å¼•å‘æ–°ä¸€è½®AIç›‘ç®¡è®¨è®ºã€‚",
        images=["https://example.com/gpt5-launch.jpg"],
        video_urls=["https://youtube.com/watch?v=example"],
        language="en",
        mentioned_people=["Sam Altman"]
    )
    
    prediction = Prediction(
        category=Category.AI,
        timeframe="week",
        content="å…³æ³¨GPT-5å‘å¸ƒåçš„å¸‚åœºååº”å’Œç«äº‰å¯¹æ‰‹å›åº”ï¼›Googleå¯èƒ½åŠ é€ŸGemini 2.0å‘å¸ƒè®¡åˆ’ã€‚",
        created_at=datetime.now()
    )
    
    change = PredictionChange(
        category=Category.AI,
        timeframe="week",
        old_content="ç­‰å¾…OpenAIæ–°æ¨¡å‹å‘å¸ƒæ¶ˆæ¯",
        new_content="å…³æ³¨GPT-5å‘å¸ƒåçš„å¸‚åœºååº”",
        reason="GPT-5å·²æ­£å¼å‘å¸ƒï¼Œå…³æ³¨é‡ç‚¹è½¬å‘å¸‚åœºååº”",
        changed_at=datetime.now()
    )
    
    briefing = DailyBriefing(
        date=datetime(2026, 2, 13),
        articles_by_category={Category.AI: [article]},
        predictions=[prediction],
        prediction_changes=[change],
        summary="ä»Šæ—¥æœ€é‡è¦æ–°é—»ï¼šOpenAIå‘å¸ƒGPT-5ï¼Œæ ‡å¿—ç€AIèƒ½åŠ›çš„åˆä¸€æ¬¡é‡å¤§çªç ´ã€‚"
    )
    
    # ç”ŸæˆMarkdown
    md_gen = MarkdownGenerator()
    filepath = md_gen.save(briefing)
    print(f"Generated: {filepath}")
    
    # æ‰“å°é¢„è§ˆ
    content = md_gen.generate(briefing)
    print(content[:2000])


if __name__ == "__main__":
    asyncio.run(main())
